{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ✅ Data Integrity Check\n",
                "\n",
                "Before we dive into behavioral modeling, we need to ensure our foundation is solid. This notebook validates the processed trip data, specifically focusing on the casual-rider segment. We're checking for completeness, unique identifiers, and ensuring the time ranges align with our expectations."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Preparation\n",
                "We start by loading our essential libraries and defining the path to our processed data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from pathlib import Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = Path(\"../data/processed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Loading the Dataset\n",
                "We load the `fact_trips.csv` file, specifically pulling in the station names, timestamps, and rider types. To ensure accuracy, we'll calculate the 'hour' feature on the fly from the raw timestamps."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Running Data Integrity Check (Casual-Only Analysis Readiness)...\n"
                    ]
                }
            ],
            "source": [
                "file_path = DATA_DIR / \"fact_trips.csv\"\n",
                "\n",
                "if not file_path.exists():\n",
                "    raise FileNotFoundError(\"\\u274c fact_trips.csv not found. Run pipeline first.\")\n",
                "\n",
                "print(\"Running Data Integrity Check (Casual-Only Analysis Readiness)...\")\n",
                "\n",
                "df = pd.read_csv(file_path, usecols=['start_station_name', 'started_at', 'member_casual'])\n",
                "df['hour'] = pd.to_datetime(df['started_at']).dt.hour\n",
                "casual_df = df[df['member_casual'] == 'casual']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Running Validation Checks\n",
                "Now, we execute our health checks. We're looking at the total volume of casual rides, checking for any missing station names, and verifying that the hourly data spans the full daily cycle."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--------------------------------------------------\n",
                        "Total Casual Rides: 1,568,655\n",
                        "Missing Station Names: 0 (0.00%)\n",
                        "Unique Stations: 1697\n",
                        "Time Range Validated: 0h to 23h\n",
                        "✅ SUCCESS: Data integrity verified for behavioral modeling.\n"
                    ]
                }
            ],
            "source": [
                "missing_stations = casual_df['start_station_name'].isna().sum()\n",
                "unique_stations = casual_df['start_station_name'].nunique()\n",
                "\n",
                "print(\"-\" * 50)\n",
                "print(f\"Total Casual Rides: {len(casual_df):,}\")\n",
                "print(f\"Missing Station Names: {missing_stations:,} ({(missing_stations/len(casual_df))*100:.2f}%)\")\n",
                "print(f\"Unique Stations: {unique_stations}\")\n",
                "print(f\"Time Range Validated: {casual_df['hour'].min()}h to {casual_df['hour'].max()}h\")\n",
                "\n",
                "if missing_stations > (0.25 * len(casual_df)):\n",
                "    print(\"\\u26a0\\ufe0f WARNING: High null count in station names. Clean the source data.\")\n",
                "else:\n",
                "    print(\"\\u2705 SUCCESS: Data integrity verified for behavioral modeling.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}