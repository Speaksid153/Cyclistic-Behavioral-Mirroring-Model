{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Station Segmentation: Defining the Behavioral Portfolio\n",
                "\n",
                "This notebook categorizes bike stations based on their habitual density and consistency. By aggregating refined behavioral scores across multiple months, we identify 'Confirmed Behavioral Anchors'—stations where casual riders consistently mimic commuter behavior—and differentiate them from high-potential emerging sites or inconsistent noise."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Configuration\n",
                "\n",
                "Define the input directory for behavioral scores and the output path for segmented results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "\n",
                "\n",
                "DATA_DIR = Path(\"../data/processed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Segmentation Framework\n",
                "\n",
                "The segmentation process involves two primary dimensions:\n",
                "1. **Density Score**: The percentage of months a station was classified as a 'Strong Mirror'.\n",
                "2. **Consistency Score**: The mean routine score across all observed months.\n",
                "\n",
                "Stations are then classified into one of three tiers: **Confirmed Behavioral Anchor**, **High-Potential Emerging**, or **Inconsistent / Noise** based on their density score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_station_segmentation():\n",
                "    input_path = DATA_DIR / \"refined_behavioral_scores.csv\"\n",
                "    output_path = DATA_DIR / \"station_behavior_segments.csv\"\n",
                "\n",
                "    if not input_path.exists():\n",
                "        print(f\"❌ Error: {input_path} not found.\")\n",
                "        return\n",
                "\n",
                "    df = pd.read_csv(input_path)\n",
                "\n",
                "\n",
                "    density_df = (\n",
                "        df.groupby(\"start_station_name\")[\"mirror_verdict\"]\n",
                "        .apply(lambda x: (x == \"Strong Mirror\").sum() / len(x))\n",
                "        .reset_index(name=\"density_score\")\n",
                "    )\n",
                "\n",
                "\n",
                "    consistency_df = (\n",
                "        df.groupby(\"start_station_name\")[\"routine_score\"]\n",
                "        .mean()\n",
                "        .reset_index(name=\"consistency_score\")\n",
                "    )\n",
                "\n",
                "    final_df = density_df.merge(consistency_df, on=\"start_station_name\")\n",
                "\n",
                "    def classify_station(density):\n",
                "        if density >= 0.60:  \n",
                "            return \"Confirmed Behavioral Anchor\"\n",
                "        elif density >= 0.30: \n",
                "            return \"High-Potential Emerging\"\n",
                "        else:\n",
                "            return \"Inconsistent / Noise\"\n",
                "\n",
                "    final_df[\"final_status\"] = final_df[\"density_score\"].apply(classify_station)\n",
                "    final_df = final_df.sort_values(\"consistency_score\", ascending=False)\n",
                "    final_df.to_csv(output_path, index=False)\n",
                "\n",
                "    print(\"-\" * 50)\n",
                "    print(f\"✅ SUCCESS: High-density segments saved to {output_path}\")\n",
                "    print(\"\\nNew Portfolio Distribution:\")\n",
                "    print(final_df[\"final_status\"].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Execution\n",
                "\n",
                "Execute the station segmentation process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--------------------------------------------------\n",
                        "✅ SUCCESS: High-density segments saved to ..\\data\\processed\\station_behavior_segments.csv\n",
                        "\n",
                        "New Portfolio Distribution:\n",
                        "final_status\n",
                        "Inconsistent / Noise           491\n",
                        "High-Potential Emerging          5\n",
                        "Confirmed Behavioral Anchor      4\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "if __name__ == \"__main__\":\n",
                "    run_station_segmentation()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
