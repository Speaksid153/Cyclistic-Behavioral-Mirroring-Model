{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Station Segmentation\n",
                "Classifies stations into **Confirmed Behavioral Anchor**, **High-Potential Emerging**, or **Inconsistent / Noise** based on density and consistency scores."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from pathlib import Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 3,489 rows.\n"
                    ]
                }
            ],
            "source": [
                "DATA_DIR = Path(\"../data/processed\")\n",
                "input_path = DATA_DIR / \"refined_behavioral_scores.csv\"\n",
                "output_path = DATA_DIR / \"station_behavior_segments.csv\"\n",
                "\n",
                "if not input_path.exists():\n",
                "    raise FileNotFoundError(\"\\u274c refined_behavioral_scores.csv not found.\")\n",
                "\n",
                "df = pd.read_csv(input_path)\n",
                "print(f\"Loaded {len(df):,} rows.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Unique stations: 500\n"
                    ]
                }
            ],
            "source": [
                "# 1. Density Score\n",
                "density_df = (\n",
                "    df.groupby(\"start_station_name\")[\"mirror_verdict\"]\n",
                "    .apply(lambda x: (x == \"Strong Mirror\").sum() / len(x))\n",
                "    .reset_index(name=\"density_score\")\n",
                ")\n",
                "\n",
                "# 2. Consistency Score\n",
                "consistency_df = (\n",
                "    df.groupby(\"start_station_name\")[\"routine_score\"]\n",
                "    .mean()\n",
                "    .reset_index(name=\"consistency_score\")\n",
                ")\n",
                "\n",
                "final_df = density_df.merge(consistency_df, on=\"start_station_name\")\n",
                "print(f\"Unique stations: {len(final_df)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--------------------------------------------------\n",
                        "âœ… SUCCESS: Segments saved to ..\\data\\processed\\station_behavior_segments.csv\n",
                        "\n",
                        "Portfolio Distribution:\n",
                        "final_status\n",
                        "Inconsistent / Noise           491\n",
                        "High-Potential Emerging          5\n",
                        "Confirmed Behavioral Anchor      4\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# --- TIGHTENED LOGIC ---\n",
                "def classify_station(density):\n",
                "    if density >= 0.60:  # Must be a Strong Mirror 60%+ of the time\n",
                "        return \"Confirmed Behavioral Anchor\"\n",
                "    elif density >= 0.30:\n",
                "        return \"High-Potential Emerging\"\n",
                "    else:\n",
                "        return \"Inconsistent / Noise\"\n",
                "\n",
                "final_df[\"final_status\"] = final_df[\"density_score\"].apply(classify_station)\n",
                "final_df = final_df.sort_values(\"consistency_score\", ascending=False)\n",
                "final_df.to_csv(output_path, index=False)\n",
                "\n",
                "print(\"-\" * 50)\n",
                "print(f\"\\u2705 SUCCESS: Segments saved to {output_path}\")\n",
                "print(\"\\nPortfolio Distribution:\")\n",
                "print(final_df[\"final_status\"].value_counts())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
