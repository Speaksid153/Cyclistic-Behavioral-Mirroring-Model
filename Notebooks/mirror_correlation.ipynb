{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Mirror Correlation Analysis\n",
                "\n",
                "This notebook measures the behavioral alignment between casual and member riders at identified anchor stations. By calculating the Pearson correlation of their hourly ride distributions, we can confirm which stations exhibit a 'strong mirror' effect, indicating that casual riders at these locations share the same habitual patterns as commuters."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Configuration\n",
                "\n",
                "Define the paths for the input and output data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "\n",
                "\n",
                "DATA_DIR = Path(\"../data/processed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Correlation Analysis Logic\n",
                "\n",
                "The function below perform the following steps:\n",
                "1. **Data Loading**: Loads trip data and derives the 'hour' feature.\n",
                "2. **Anchor Selection**: Filters for 'Confirmed Behavioral Anchors' from previous segmentation.\n",
                "3. **Distribution Calculation**: Computes normalized hourly ride counts (0-23h) for both casuals and members at each anchor station.\n",
                "4. **Correlation Measurement**: Uses Pearson Correlation to quantify the similarity between the two distributions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_mirror_correlation():\n",
                " \n",
                "    master_path = DATA_DIR / \"fact_trips.csv\"\n",
                "    anchor_path = DATA_DIR / \"station_behavior_segments.csv\"\n",
                "    output_path = DATA_DIR / \"mirror_correlation_results.csv\"\n",
                "    \n",
                "   \n",
                "    if not master_path.exists() or not anchor_path.exists():\n",
                "        print(f\"❌ Error: Required files missing in {DATA_DIR}\")\n",
                "        return\n",
                "\n",
                "    print(\"Starting Behavioral Mirroring Analysis...\")\n",
                "    \n",
                " \n",
                "    df = pd.read_csv(master_path, usecols=['start_station_name', 'started_at', 'member_casual'])\n",
                "    \n",
                "    print(\"Converting timestamps and deriving hour...\")\n",
                "    df['started_at'] = pd.to_datetime(df['started_at'])\n",
                "    df['hour'] = df['started_at'].dt.hour\n",
                "    \n",
                "  \n",
                "    anchors = pd.read_csv(anchor_path)\n",
                "    elite_anchors = anchors[anchors['final_status'] == 'Confirmed Behavioral Anchor']['start_station_name'].tolist()\n",
                "    \n",
                "    if not elite_anchors:\n",
                "        print(\"⚠️ No 'Confirmed Behavioral Anchors' found. Check your segmentation thresholds.\")\n",
                "        return\n",
                "\n",
                "    results = []\n",
                "    for station in elite_anchors:\n",
                "        subset = df[df['start_station_name'] == station]\n",
                "        \n",
                "        \n",
                "        casual_dist = subset[subset['member_casual'] == 'casual']['hour'].value_counts(normalize=True).sort_index()\n",
                "        member_dist = subset[subset['member_casual'] == 'member']['hour'].value_counts(normalize=True).sort_index()\n",
                "        \n",
                "      \n",
                "        full_index = pd.Index(range(24))\n",
                "        casual_dist = casual_dist.reindex(full_index, fill_value=0)\n",
                "        member_dist = member_dist.reindex(full_index, fill_value=0)\n",
                "        \n",
                "      \n",
                "        correlation = casual_dist.corr(member_dist)\n",
                "        \n",
                "        results.append({\n",
                "            \"Station\": station,\n",
                "            \"Mirror_Correlation\": round(correlation, 4),\n",
                "            \"Verdict\": \"Strong Mirror\" if correlation >= 0.85 else \"Weak Alignment\"\n",
                "        })\n",
                "\n",
                "  \n",
                "    mirror_df = pd.DataFrame(results).sort_values(by=\"Mirror_Correlation\", ascending=False)\n",
                "    mirror_df.to_csv(output_path, index=False)\n",
                "    \n",
                "    print(\"-\" * 50)\n",
                "    print(\"ELITE ANCHOR CORRELATION RESULTS:\")\n",
                "    print(mirror_df.to_string(index=False))\n",
                "    print(f\"\\n✅ SUCCESS: Mirror analysis saved to {output_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Execution\n",
                "\n",
                "Execute the mirror correlation analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting Behavioral Mirroring Analysis...\n",
                        "Converting timestamps and deriving hour...\n",
                        "--------------------------------------------------\n",
                        "ELITE ANCHOR CORRELATION RESULTS:\n",
                        "                         Station  Mirror_Correlation        Verdict\n",
                        "Wacker Dr & Washington St Corral              0.9881  Strong Mirror\n",
                        "    Clinton St & Washington Blvd              0.9068  Strong Mirror\n",
                        "       Artesian Ave & Hubbard St              0.7820 Weak Alignment\n",
                        "                       NAVY PIER              0.7257 Weak Alignment\n",
                        "\n",
                        "✅ SUCCESS: Mirror analysis saved to ..\\data\\processed\\mirror_correlation_results.csv\n"
                    ]
                }
            ],
            "source": [
                "if __name__ == \"__main__\":\n",
                "    run_mirror_correlation()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
