{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Habitual Analysis: Identifying Commuter-Like Casuals\n",
                "\n",
                "This notebook analyzes casual ride patterns to identify habits that mimic member behavior. It specifically looks at rush-hour concentration ($C_h$) and mid-week focus ($C_d$) to score stations based on their 'routine' strength."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Configuration\n",
                "\n",
                "Define the target data directory and the specific hours designated as the 'Rush Window' (Morning and Evening peaks)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "\n",
                "\n",
                "DATA_DIR = Path(\"../data/processed\")\n",
                "RUSH_WINDOW = [7, 8, 9, 17, 18, 19]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Habitual Metrics Model\n",
                "\n",
                "The core analysis involves:\n",
                "1. **Volume Filtering**: Focusing on top 25% active stations to ensure statistical relevance.\n",
                "2. **Hourly Consistency ($C_h$)**: Calculating the proportion of rides occurring during rush hours.\n",
                "3. **Mid-week Focus ($C_d$)**: Calculating the frequency of rides on Tuesday, Wednesday, and Thursday.\n",
                "4. **Final Scoring**: A weighted score (60% $C_h$ + 40% $C_d$) to determine the overall Routine Score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_habitual_analysis():\n",
                "    input_path = DATA_DIR / \"fact_trips.csv\"\n",
                "    if not input_path.exists():\n",
                "        print(\"❌ Error: fact_trips.csv not found. Run pipeline.py first.\")\n",
                "        return\n",
                "\n",
                "    \n",
                "    df = pd.read_csv(input_path, usecols=['start_station_name', 'started_at', 'member_casual', 'is_commute'])\n",
                "    \n",
                "    \n",
                "    df = df[df['member_casual'] == 'casual'].copy()\n",
                "    df['started_at'] = pd.to_datetime(df['started_at'])\n",
                "    df['month'] = df['started_at'].dt.month_name()\n",
                "    df['hour'] = df['started_at'].dt.hour\n",
                "    df['day_name'] = df['started_at'].dt.day_name()\n",
                "\n",
                "    print(f\"Analyzing habitual patterns for {len(df):,} casual rides...\")\n",
                "\n",
                "   \n",
                "    station_monthly_vol = df.groupby(['start_station_name', 'month']).size().reset_index(name='vol')\n",
                "    vol_threshold = station_monthly_vol['vol'].quantile(0.75) \n",
                "    valid_stations = station_monthly_vol[station_monthly_vol['vol'] >= vol_threshold]\n",
                "    \n",
                "    \n",
                "    df['in_rush'] = df['hour'].isin(RUSH_WINDOW).astype(int)\n",
                "    ch_scores = df.groupby(['start_station_name', 'month'])['in_rush'].mean().reset_index(name='Ch')\n",
                "\n",
                "    \n",
                "    midweek_days = ['Tuesday', 'Wednesday', 'Thursday']\n",
                "    df['is_midweek'] = df['day_name'].isin(midweek_days).astype(int)\n",
                "    cd_scores = df.groupby(['start_station_name', 'month'])['is_midweek'].mean().reset_index(name='Cd')\n",
                "\n",
                "    \n",
                "    results = valid_stations.merge(ch_scores, on=['start_station_name', 'month'])\n",
                "    results = results.merge(cd_scores, on=['start_station_name', 'month'])\n",
                "    results['routine_score'] = (results['Ch'] * 0.6) + (results['Cd'] * 0.4)\n",
                "    \n",
                "    \n",
                "    results['tier'] = pd.cut(\n",
                "        results['routine_score'], \n",
                "        bins=[0, 0.25, 0.45, 1.0], \n",
                "        labels=['Low', 'Emerging', 'Strong']\n",
                "    )\n",
                "\n",
                "    output_path = DATA_DIR / \"habitual_metrics.csv\"\n",
                "    results.sort_values('routine_score', ascending=False).to_csv(output_path, index=False)\n",
                "    print(f\"✅ SUCCESS: Habitual metrics saved to {output_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Execution\n",
                "\n",
                "Execute the habitual analysis process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Analyzing habitual patterns for 1,568,655 casual rides...\n",
                        "✅ SUCCESS: Habitual metrics saved to ..\\data\\processed\\habitual_metrics.csv\n"
                    ]
                }
            ],
            "source": [
                "if __name__ == \"__main__\":\n",
                "    run_habitual_analysis()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
