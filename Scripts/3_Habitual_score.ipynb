{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Habitual Score Calculation\n",
                "This notebook calculates habitual scores for casual riders, identifying potential candidates for conversion to annual membership."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "\n",
                "# =========================\n",
                "# 1. PATH SETUP (PORTABLE)\n",
                "# =========================\n",
                "SCRIPT_DIR = Path().resolve()\n",
                "PROJECT_ROOT = SCRIPT_DIR.parent \n",
                "\n",
                "input_path = PROJECT_ROOT / 'Data' / 'Processed Datasets' / 'cyclistic_casual_only.csv'\n",
                "output_path = PROJECT_ROOT / 'Data' / 'Processed Datasets' / 'monthly_conversion_metrics.csv'\n",
                "\n",
                "print(\"Starting Cyclistic Casual Habitual Conversion Analysis...\")\n",
                "\n",
                "# Safety check\n",
                "if not input_path.exists():\n",
                "    print(f\"âŒ ERROR: Missing {input_path}. Did you run script #2?\")\n",
                "    # exit() # Commented out for notebook"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =========================\n",
                "# 2. DATA LOADING & CLEANING\n",
                "# =========================\n",
                "df = pd.read_csv(input_path)\n",
                "print(f\"Step 1: Data loaded. Total rows: {len(df):,}\")\n",
                "\n",
                "# Drop missing start stations (can't analyze behavior without location)\n",
                "casuals = df.dropna(subset=['start_station_name']).copy()\n",
                "print(f\"Step 2: Dropped rows with missing stations. Rows remaining: {len(casuals):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =========================\n",
                "# 3. FREQUENCY GATE\n",
                "# =========================\n",
                "# Why? We only care about stations where casual riders appear consistently.\n",
                "casuals['station_month_count'] = casuals.groupby(['start_station_name', 'month'])['hour'].transform('count')\n",
                "VOLUME_FLOOR = 100\n",
                "casuals = casuals[casuals['station_month_count'] >= VOLUME_FLOOR]\n",
                "print(f\"Step 3: Applied Frequency Gate (>= {VOLUME_FLOOR} rides/month). Rows remaining: {len(casuals):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =========================\n",
                "# 4. HOURLY CONSISTENCY (Ch)\n",
                "# =========================\n",
                "# Logic: If a large % of rides happen in the same 2-hour window, it's a routine.\n",
                "casuals['hour_bin'] = (casuals['hour'] // 2) * 2\n",
                "bin_counts = casuals.groupby(['start_station_name', 'month', 'hour_bin']).size().reset_index(name='bin_vol')\n",
                "total_vol = bin_counts.groupby(['start_station_name', 'month'])['bin_vol'].transform('sum')\n",
                "bin_counts['bin_share'] = bin_counts['bin_vol'] / total_vol\n",
                "\n",
                "# Ch = The percentage of the busiest 2-hour block\n",
                "ch_scores = bin_counts.groupby(['start_station_name', 'month'])['bin_share'].max().reset_index(name='Ch')\n",
                "print(\"Step 4: Hourly consistency (Ch) calculated.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =========================\n",
                "# 5. MID-WEEK FOCUS (Cd)\n",
                "# =========================\n",
                "# Logic: Casuals riding Tue/Wed/Thu are likely commuting.\n",
                "midweek_names = ['Tuesday', 'Wednesday', 'Thursday']\n",
                "casuals['is_midweek'] = casuals['day_of_week'].isin(midweek_names).astype(int)\n",
                "cd_scores = casuals.groupby(['start_station_name', 'month'])['is_midweek'].mean().reset_index(name='Cd')\n",
                "print(\"Step 5: Mid-week focus (Cd) calculated.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =========================\n",
                "# 6. ROUTINE SCORE (RS) & TIERING\n",
                "# =========================\n",
                "results = ch_scores.merge(cd_scores, on=['start_station_name', 'month'])\n",
                "\n",
                "# Weighted Score: 60% Hourly Consistency, 40% Mid-week focus\n",
                "results['RS'] = (results['Ch'] * 0.6) + (results['Cd'] * 0.4)\n",
                "\n",
                "def assign_tier(rs):\n",
                "    if rs >= 0.35: return 'Strong'\n",
                "    elif rs >= 0.25: return 'Emerging'\n",
                "    else: return 'Low'\n",
                "\n",
                "results['Tier'] = results['RS'].apply(assign_tier)\n",
                "results = results.sort_values(by='RS', ascending=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =========================\n",
                "# 7. SAVE RESULTS\n",
                "# =========================\n",
                "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
                "results.to_csv(output_path, index=False)\n",
                "\n",
                "print(\"-\" * 40)\n",
                "print(f\"ANALYSIS COMPLETE. Results saved to: {output_path}\")\n",
                "print(\"\\nTOP 10 CONVERSION TARGETS (By Routine Score):\")\n",
                "print(results.head(10))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}