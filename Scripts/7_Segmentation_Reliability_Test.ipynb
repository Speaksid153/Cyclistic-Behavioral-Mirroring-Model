{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 7. Segmentation Reliability Test\n",
                "This notebook calculates statistical metrics (Concentration and Peakiness) to validate the behavioral differences between segments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import sys\n",
                "\n",
                "# --- Setup GitHub-Ready Paths ---\n",
                "# This finds the root project folder regardless of whose computer it is on\n",
                "BASE_DIR = Path().resolve().parent\n",
                "INPUT_PATH = BASE_DIR / \"Data\" / \"Processed Datasets\" / \"casual_anchor_vs_noise_hourly.csv\"\n",
                "OUTPUT_PATH = BASE_DIR / \"Data\" / \"Processed Datasets\" / \"behavioral_concentration_metrics.csv\"\n",
                "\n",
                "print(\"Starting Concentration Metrics Validation...\")\n",
                "\n",
                "# --- Load Data ---\n",
                "if not INPUT_PATH.exists():\n",
                "    print(f\"CRITICAL ERROR: Could not find dataset at {INPUT_PATH}\")\n",
                "    print(\"Check your folder structure. Expected: Project_Root/Data/Processed Datasets/\")\n",
                "    # sys.exit(1) # Commented out for notebook\n",
                "else:\n",
                "    hourly_df = pd.read_csv(INPUT_PATH)\n",
                "    results = []\n",
                "\n",
                "    # --- Calculation Engine ---\n",
                "    for segment in hourly_df['final_status'].unique():\n",
                "        segment_data = hourly_df[hourly_df['final_status'] == segment]\n",
                "        \n",
                "        # Identify the 'peaks'\n",
                "        sorted_by_val = segment_data.sort_values(by='percentage', ascending=False)\n",
                "        \n",
                "        # Metric 1: Concentration (Top 2 hours sum)\n",
                "        top2_concentration = sorted_by_val.head(2)['percentage'].sum()\n",
                "        \n",
                "        # Metric 2: Hourly Std Deviation (Peakiness)\n",
                "        std_dev = segment_data['percentage'].std()\n",
                "        \n",
                "        results.append({\n",
                "            \"Segment\": segment,\n",
                "            \"Top 2 Hour Concentration (%)\": round(top2_concentration, 2),\n",
                "            \"Hourly Std Deviation\": round(std_dev, 2)\n",
                "        })\n",
                "\n",
                "    metrics_df = pd.DataFrame(results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Analysis & Comparison ---\n",
                "if 'metrics_df' in locals():\n",
                "    print(\"\\n\" + \"=\"*40)\n",
                "    print(\"STATISTICAL VALIDATION RESULTS\")\n",
                "    print(\"=\"*40)\n",
                "    print(metrics_df.to_string(index=False))\n",
                "\n",
                "    # Ensure output directory exists and save\n",
                "    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
                "    metrics_df.to_csv(OUTPUT_PATH, index=False)\n",
                "    print(f\"\\nResults saved to: {OUTPUT_PATH}\")\n",
                "\n",
                "    # --- The \"Behavioral Gap\" Logic ---\n",
                "    anchor_stats = metrics_df[metrics_df['Segment'] == 'Confirmed Behavioral Anchor']\n",
                "    noise_stats = metrics_df[metrics_df['Segment'] == 'Inconsistent / Noise']\n",
                "\n",
                "    if not anchor_stats.empty and not noise_stats.empty:\n",
                "        a_conc = anchor_stats['Top 2 Hour Concentration (%)'].values[0]\n",
                "        n_conc = noise_stats['Top 2 Hour Concentration (%)'].values[0]\n",
                "        ratio = a_conc / n_conc\n",
                "        \n",
                "        print(\"\\n\" + \"-\"*40)\n",
                "        print(f\"FINAL BEHAVIORAL GAP: {ratio:.2f}x\")\n",
                "        \n",
                "        if ratio >= 1.5:\n",
                "            print(\"DECISION: ELITE SEPARATION - Segmentation Validated.\")\n",
                "        elif ratio >= 1.25:\n",
                "            print(\"DECISION: CLEAR SEPARATION - Habits identified.\")\n",
                "        else:\n",
                "            print(\"DECISION: WEAK SEPARATION - Adjust Routine Score thresholds.\")\n",
                "        print(\"-\"*40)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}